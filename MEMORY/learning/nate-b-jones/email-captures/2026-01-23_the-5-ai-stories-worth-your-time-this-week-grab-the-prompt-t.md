# The 5 AI stories worth your time this week + grab the prompt that turns news into a 14-day experiment

**Date:** 2026-01-23
**Source:** Email (paid subscriber content)
**Captured:** 2026-01-24T04:28:43.861Z

---

The 5 AI stories worth your time this week + grab the prompt that turns news into a 14-day experiment







**









From:
**Nate from Nate’s Substack <natesnewsletter@substack.com> on behalf of Nate from Nate’s Substack <natesnewsletter@substack.com>**
Reply-To: **Nate from Nate’s Substack <reply+320j6e&8r1h1&&731b9b0173ac3e302e58a883d962cffbcdb193b7c52d4df13bba7b807ab60f31@mg1.substack.com>**
Date: **Saturday, January 17, 2026 at 8:05 AM**
To: **Doug Snyder <dsnyder@cydcor.com>**
Subject: **The 5 AI stories worth your time this week + grab the prompt that turns news into a 14-day experiment












This email has been sent from an external source










Watch now | From a healthcare race that’s partly defensive and partly IPO positioning to a departure that exposes a fundamental disagreement. Here's what mattered
this week.




͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­͏
­























[View
in browser](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9uYXRlc25ld3NsZXR0ZXIuc3Vic3RhY2suY29tL3AvaS1yZWFkLTIwMC1haS1hbm5vdW5jZW1lbnRzLXNvLXlvdT91dG1fY2FtcGFpZ249ZW1haWwtcG9zdCZyPThyMWgxJnRva2VuPWV5SjFjMlZ5WDJsa0lqb3hORFk1T0RVME9Td2ljRzl6ZEY5cFpDSTZNVGcwTnpneU5qRTBMQ0pwWVhRaU9qRTNOamcyTmpVNU1Ua3NJbVY0Y0NJNk1UYzNNVEkxTnpreE9Td2lhWE56SWpvaWNIVmlMVEV6TnpNeU16RWlMQ0p6ZFdJaU9pSndiM04wTFhKbFlXTjBhVzl1SW4wLmdLcGpveE90Z21SRS1MUElXRWpnczhpcC1fQnliWlhnUGZDTXVlYnRRUFEiLCJwIjoxODQ3ODI2MTQsInMiOjEzNzMyMzEsImYiOmZhbHNlLCJ1IjoxNDY5ODU0OSwiaWF0IjoxNzY4NjY1OTE5LCJleHAiOjIwODQyNDE5MTksImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.1MtWVChKZaOTbDpf9RM19bAtpVCyN24vpE1ej1qx6xo?)














Look at you getting killer career perspective and the full AI picture. Give yourself a pat on the back for diving in on AI and go get a coffee
☕












[](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=podcast-email&play_audio=true&r=8r1h1&utm_campaign=email-play-on-substack&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MTc3MTI1NzkxOSwiaXNzIjoicHViLTEzNzMyMzEiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.gKpjoxOtgmRE-LPIWEjgs8ip-_BybZXgPfCMuebtQPQ&utm_content=watch_now_gif)

































[**Watch
now**](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=podcast-email&play_audio=true&r=8r1h1&utm_campaign=email-play-on-substack&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MTc3MTI1NzkxOSwiaXNzIjoicHViLTEzNzMyMzEiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.gKpjoxOtgmRE-LPIWEjgs8ip-_BybZXgPfCMuebtQPQ&utm_content=watch_now_button)




























# [The
5 AI stories worth your time this week + grab the prompt that turns news into a 14-day experiment](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=post-email-title&utm_campaign=email-post-title&isFreemail=false&r=8r1h1&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MTc3MTI1NzkxOSwiaXNzIjoicHViLTEzNzMyMzEiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.gKpjoxOtgmRE-LPIWEjgs8ip-_BybZXgPfCMuebtQPQ)


###
From a healthcare race that’s partly defensive and partly IPO positioning to a departure that exposes a fundamental disagreement. Here's what news mattered this week.
















[Nate](https://substack.com/@natesnewsletter)
















Jan 17











∙







Paid






















[](https://substack.com/@natesnewsletter)





































[](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=substack&isFreemail=false&submitLike=true&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJyZWFjdGlvbiI6IuKdpCIsImlhdCI6MTc2ODY2NTkxOSwiZXhwIjoxNzcxMjU3OTE5LCJpc3MiOiJwdWItMTM3MzIzMSIsInN1YiI6InJlYWN0aW9uIn0.fUSTde1UTZzYpF_vf5fyIUCfYwJj6zgvxAN1ZNvmq5U&utm_medium=email&utm_campaign=email-reaction&r=8r1h1)













[](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=substack&utm_medium=email&isFreemail=false&comments=true&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MTc3MTI1NzkxOSwiaXNzIjoicHViLTEzNzMyMzEiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.gKpjoxOtgmRE-LPIWEjgs8ip-_BybZXgPfCMuebtQPQ&r=8r1h1&utm_campaign=email-half-magic-comments&action=post-comment&utm_source=substack&utm_medium=email)













[](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=substack&utm_medium=email&utm_content=share&utm_campaign=email-share&action=share&triggerShare=true&isFreemail=false&r=8r1h1&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MTc3MTI1NzkxOSwiaXNzIjoicHViLTEzNzMyMzEiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.gKpjoxOtgmRE-LPIWEjgs8ip-_BybZXgPfCMuebtQPQ)













[](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9vcGVuLnN1YnN0YWNrLmNvbS9wdWIvbmF0ZXNuZXdzbGV0dGVyL3AvaS1yZWFkLTIwMC1haS1hbm5vdW5jZW1lbnRzLXNvLXlvdT91dG1fc291cmNlPXN1YnN0YWNrJnV0bV9tZWRpdW09ZW1haWwmdXRtX2NhbXBhaWduPWVtYWlsLXJlc3RhY2stY29tbWVudCZhY3Rpb249cmVzdGFjay1jb21tZW50JnI9OHIxaDEmdG9rZW49ZXlKMWMyVnlYMmxrSWpveE5EWTVPRFUwT1N3aWNHOXpkRjlwWkNJNk1UZzBOemd5TmpFMExDSnBZWFFpT2pFM05qZzJOalU1TVRrc0ltVjRjQ0k2TVRjM01USTFOemt4T1N3aWFYTnpJam9pY0hWaUxURXpOek15TXpFaUxDSnpkV0lpT2lKd2IzTjBMWEpsWVdOMGFXOXVJbjAuZ0twam94T3RnbVJFLUxQSVdFamdzOGlwLV9CeWJaWGdQZkNNdWVidFFQUSIsInAiOjE4NDc4MjYxNCwicyI6MTM3MzIzMSwiZiI6ZmFsc2UsInUiOjE0Njk4NTQ5LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MjA4NDI0MTkxOSwiaXNzIjoicHViLTAiLCJzdWIiOiJsaW5rLXJlZGlyZWN0In0.5Re15-XnH2TuelV58mbGo5GOCZ11V5mO0IkJy-VzOJ8?&utm_source=substack&utm_medium=email)






















[](https://open.substack.com/pub/natesnewsletter/p/i-read-200-ai-announcements-so-you?utm_source=email&redirect=app-store&utm_campaign=email-read-in-app)


[READ
IN APP](https://open.substack.com/pub/natesnewsletter/p/i-read-200-ai-announcements-so-you?utm_source=email&redirect=app-store&utm_campaign=email-read-in-app)































Every week I spend hours tracking what’s actually happening in AI—not the headlines, but the strategic shifts underneath them. The past two weeks had over 200 announcements. Five of them matter: a healthcare race that’s partly defensive
and partly about IPO positioning, a departure that exposes a fundamental disagreement about where AI is headed, a physical AI convergence that’s forming the first real flywheel, a training data scramble that reveals what’s actually scarce, and a capability
tipping point that just produced a browser in a week. This is what’s worth your attention and what it tells us about where this is all going.



Two weeks ago, OpenAI announced a healthcare product. Five days later, Anthropic announced one too. The same week, Nvidia unveiled its next-generation chip architecture at CES. Google DeepMind announced a partnership with Boston
Dynamics. Yann LeCun departed Meta with a parting shot that LLMs are “a dead end for superintelligence.” And buried in the noise, OpenAI started asking contractors to upload real work from their previous jobs.



Read superficially, these are separate stories. Read carefully, they’re all the same story: the AI industry is discovering what actually compounds, and it’s not what most people think.



Top Stories this week:


-
OpenAI and Anthropic both launched healthcare products within five days—partly defensive, partly IPO positioning
-
Yann LeCun departed Meta, called LLMs “a dead end for superintelligence,” and revealed Meta “fudged” their Llama 4 benchmarks
-
Nvidia launched the Rubin platform at CES; Google DeepMind partnered with Boston Dynamics to put Gemini in Atlas robots
-
OpenAI and Handshake AI are asking contractors to upload real work from previous employers—the easy training data is exhausted
-
Cursor built a browser from scratch using GPT-5.2 in one week: 3 million lines of code, and it kind of works



Lots to cover so let’s get into it!






Subscribers get all posts like these!





[**Subscribed**](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9uYXRlc25ld3NsZXR0ZXIuc3Vic3RhY2suY29tL2FjY291bnQiLCJwIjoxODQ3ODI2MTQsInMiOjEzNzMyMzEsImYiOmZhbHNlLCJ1IjoxNDY5ODU0OSwiaWF0IjoxNzY4NjY1OTE5LCJleHAiOjIwODQyNDE5MTksImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.-E4i11h59llUHNVHRNPD0-bQ_F3CGEePN3euNbZHSmQ?)





##
**Story 1: The Healthcare Race Is Partly Defensive, Partly Positioning**



**What happened:**



Let’s start with what OpenAI and Anthropic actually did, because the press coverage missed the point entirely.



OpenAI launched two products: ChatGPT Health for consumers (sync your health data, ask questions about your body) and OpenAI for Healthcare for enterprises (HIPAA-compliant API, hospital system integrations). Anthropic followed five
days later with Claude for Healthcare, featuring connectors to CMS databases and insurance claims systems.



The surface story is “AI comes to medicine.” But there’s a more immediate explanation that’s easy to overlook: consumers already talk to LLMs about health constantly. We can see it in the chat volume. People ask about symptoms, medications,
diet, exercise—personal health is one of the most common use cases. And if you’re running a consumer AI product where people are discussing sensitive health matters, you have a higher standard of care to exercise. The defensive read of these launches is that
they’re simply building the infrastructure to do responsibly what users are already doing.



But I think there’s another story here too. The graveyard of healthcare AI is vast and well-populated. IBM Watson did an oncology product that was supposed to revolutionize cancer care. It got sold for parts in 2022. Google’s DeepMind
has done impressive work on protein folding, but none of it has translated into clinical products reaching millions of people yet. So the natural question when AI companies launch healthcare products is: what’s different now?



Here’s what I think nobody is talking about: both companies are approaching the public markets and they need a story that’s different from “chatbot for consumers.” Healthcare provides a compelling IPO narrative whether or not the
products succeed at scale.



**Who’s involved:**



Think about what healthcare offers to investors: a regulated industry (suggests seriousness), HIPAA compliance (suggests technical sophistication), hospital partnerships (suggests enterprise credibility), and rising healthcare spend
in the US (suggests revenue growth). If you want that narrative ready for public markets, you have to start now—building partnerships, accumulating healthcare data, demonstrating millions of users benefiting. That narrative takes time to develop.



Now I want to be careful here. I’m not saying the healthcare products are vaporware—I’m saying the opposite. The prior authorization use case Anthropic highlighted, where a doctor submits paperwork to an insurance company for treatment
approval, represents a $30 billion annual administrative burden. That’s a real business. Many things can be true at once: these products respond to genuine consumer demand and they position these companies for a growing spend category as they start courting
public investors, whether that’s late 2026 or late 2027.



**Why it matters:**



The larger strategic question is what happens to the healthcare AI market if both major foundation model companies are competing directly. Every healthcare AI startup just had their build-versus-buy calculation rewritten. Why would
a hospital system partner with a healthcare AI startup when they can get HIPAA-compliant Claude or ChatGPT directly from the source?



This matters beyond healthcare. AI makes it easy to build new features quickly if you have distribution—which both OpenAI and Anthropic do. When they see a successful pattern, they can build into that space fast. Foundation model
companies are moving down the stack into vertical applications. They’re not content to be the API that startups build on. They want the application revenue too.



**What to watch:**



If you’re building an AI startup in any vertical, the question to ask yourself is: what happens when OpenAI launches a competing product with the same underlying model and their distribution? What’s our differentiator at that point?



The healthcare announcements are partly about healthcare, but they’re also about vertical integration and IPO positioning. That’s the story getting overlooked.







##
**Story 2: What Yann LeCun’s Departure Actually Means**



**What happened:**



Yann LeCun left Meta after more than a decade, and he said a lot on the way out.



Let me give you the context. LeCun is one of three people credited with the deep learning revolution—alongside Geoffrey Hinton and Yoshua Bengio. He’s not a middle manager with an opinion. He’s one of the founders of the entire field.



Here’s what he said in his Financial Times interview. First, he confirmed that Meta “fudged” their Llama 4 benchmarks, using different model variants for different tests to inflate scores. Second, he said Mark Zuckerberg “basically
lost confidence in everyone who was involved” in the Llama 4 release and “sidelined the entire GenAI organization.” The new leadership—29-year-old Alexandr Wang, brought in through Meta’s acquisition of Scale AI—LeCun called “young” and “inexperienced,” with
“no experience with research.”



Third, and most importantly: “LLMs basically are a dead end when it comes to superintelligence.”



LeCun isn’t saying LLMs won’t continue improving. He’s saying they will never reach AGI. The architecture is fundamentally limited. He’s starting a new research venture to pursue what he calls “world models”—AI systems that build
internal representations of how the world actually works, rather than predicting the next token.



**Who’s involved:**



This is one of the most fundamental disagreements in Silicon Valley, and every now and then it’s worth revisiting because someone has to be very wrong. Either LeCun is out of touch and LLMs have no scaling wall and will keep progressing
toward AGI, or he’s right and a lot of the companies pouring billions into scaling are going to hit a ceiling.



I don’t know who’s right. I’m telling you there’s a fight between some of the smartest people in the world, and we’re all going to sit on the sidelines and find out over the next couple of years. It’ll take just one or two more years
to see who’s correct about reaching AGI, which is one of the exciting things about being alive right now.



**Why it matters:**



What I do notice: we continue to see gains in agents doing longer and longer tasks. I’ll share a new record later in this piece. We haven’t seen clear gaps in the pace of generalization gains. LLMs still have fragile generalization
abilities compared to humans, but they’re getting better. Meanwhile, the benchmark manipulation at Meta suggests the scaling thesis is at least under some strain there—you don’t fudge benchmarks when the results speak for themselves.



The strategic implication isn’t to pick a side. It’s to recognize that betting everything on one scaling thesis is risky when even the people who built this technology are publicly disagreeing about whether it has a future.







##
**Story 3: The Physical AI Convergence Is Forming a Real Flywheel**



**What happened:**



At CES, Nvidia launched the Rubin platform—six new chips designed to work together as an integrated system. The same week, Google DeepMind and Boston Dynamics announced a partnership to put Gemini foundation models into Atlas robots,
with initial deployment in Hyundai factories. Nvidia unveiled its Alpamayo family of open models for autonomous vehicles. And Jensen Huang declared that “the ChatGPT moment for robotics is here.”



For the past two years, the AI story has been about language models: chatbots, coding assistants, text generation. Physical AI has been “coming soon” for decades without arriving. What changed is the convergence of three technologies
that hadn’t previously worked together.



First, foundation models can now do genuine multimodal reasoning. Gemini, GPT-4, Claude—they can look at an image and understand what’s in it, reason about spatial relationships, and generate plans. This is the perception and reasoning
layer that previous generations of robots lacked.



Second, simulation environments have become good enough to generate useful training data. Nvidia’s Omniverse can create synthetic scenarios that transfer to real-world performance. This partially solves the data problem that has
held back robotics.



Third, edge inference chips have become powerful enough to run real models on the robot itself. Nvidia’s Jetson T4000, announced at CES, delivers 4x the AI compute of previous generations in the same power envelope. The robot doesn’t
need to phone home for every decision.



**Who’s involved:**



Nvidia’s strategic play is to build the full stack for physical AI: data center training (Rubin), edge inference (Jetson), simulation (Omniverse), and open models (Alpamayo, Cosmos). They want to be the platform everyone builds robots
on, regardless of manufacturer.



The Boston Dynamics partnership is particularly interesting because it’s explicitly a data collection exercise. Gemini-powered Atlas robots will work in Hyundai factories, and the data from those deployments will train the next generation
of models. This is the flywheel beginning to turn: deploy robots, collect data, train better models, deploy better robots.



**Why it matters:**



I’ve been watching this space for a while, and what makes me more optimistic this time is the foundation model piece. Previous robot generations were brittle because they relied on hard-coded perception systems. Foundation models
are genuinely more robust to novel situations. They can reason about objects they’ve never seen. We’re seeing early indications—December 2025 and January 2026—that models are starting to learn from video how to take actions and generalize.



I think we’re at the point where the first indicators of a real flywheel are forming around robotics. A lot of the story of 2026 will be about the companies that figure out how to take the first turn or two on that flywheel, so they
can accumulate knowledge and build better robotic systems heading into 2027 and 2028.



**What to watch:**



The practical implication: if you’re in an industry that involves physical operations—manufacturing, logistics, agriculture, construction—the narrative needs to shift from “robots are coming” to “robots are here and we need to figure
out when to get one in place and start learning.” The companies that build data infrastructure and workflow integration now will be positioned when the technology crosses the deployment threshold. The companies that wait will be scrambling.







##
**Story 4: The Training Data Story Nobody Is Discussing**



**What happened:**



Buried in the news cycle was a Wired report that OpenAI and a company called Handshake AI are asking contractors to upload “real, on-the-job work” from past employers. The examples requested include Word documents, PDFs, PowerPoints,
Excel files, images, and code repositories. Contractors are told to delete proprietary and personally identifiable information before uploading.



This story got almost no attention, but it’s strategically significant.



**Why it matters:**



Here’s what it tells us: the easy training data is exhausted. The public internet has been scraped. The licensed datasets have been licensed. The synthetic data approaches have limits. The next frontier of capability improvement
requires data that doesn’t currently exist in any accessible form—the actual work products that people create in their jobs.



Think about what that means. Language models are trained on text that was written to be read—books, articles, websites, social media posts. But most of the valuable work in the economy isn’t written to be read. It’s internal documents,
project files, analysis spreadsheets, code repositories that never get open-sourced. That’s the data that would let AI actually do knowledge work, not just discuss it.



OpenAI is trying to acquire that data by paying contractors to upload their previous work. That’s a brute-force approach, and it raises obvious legal and ethical questions (does a contractor have the right to share work they did
for a previous employer?). But it reveals the strategic priority: whoever assembles the best corpus of “how people actually do work” will have a significant advantage in building AI that can do that work.



This connects to the physical AI story. The reason robot training is hard is the same reason knowledge work AI is hard: the relevant data doesn’t exist in accessible form. There’s no public dataset of “a million hours of someone
doing financial analysis” or “a million hours of a robot assembling products.” That data exists in the world, but it’s scattered across companies and individuals who have no reason to share it.



The companies solving this problem are the ones building data flywheels: deploying AI in workflows that generate data, which trains better AI, which gets deployed more widely. This is what Tesla is doing with autonomous driving.
It’s what Anthropic is doing with Claude Code. And it’s what OpenAI is apparently trying to bootstrap by paying contractors directly.



**What to watch:**



The implication for enterprises: your internal data is about to become strategically valuable in a way it never was before. The work products your employees create, the processes they follow, the edge cases they encounter—that’s
training data that could improve AI systems. The question is whether you capture that value yourself (by training custom models or building internal systems) or whether it leaks out to foundation model companies through contractors, API usage, and other channels.







##
**Story 5: The Capability Tipping Point Is Here**



**What happened:**



Claude Code blew up on X over December and into January. People were sharing workflows for everything from growing tomatoes to wiring their homes. It became an emergent phenomenon.



Boris Cherny, the creator of Claude Code, shared his own workflow this week. He runs 5-10 Claude instances simultaneously, uses Opus 4.5 exclusively, and maintains a file called CLAUDE.md where every mistake Claude makes gets converted
into a permanent rule. His Claudes get better over time.



By maintaining that markdown file with rules for Claude to review before submitting work, Boris can supervise much more lightly. Most individual attempts may fail, but because he has multiple parallel instances constantly checking
against a regularly updated rule set, he can focus on what he wants to build and let Claude iterate until it gets it right.



The frontier of what’s possible is moving even faster than that suggests. This week, Michael Truell—co-founder of Cursor—shared that they built a browser from scratch using GPT-5.2. It ran uninterrupted for one week and produced
3 million lines of code: a rendering engine in Rust with HTML parsing, CSS cascade, layout, text shaping, paint, and a custom JavaScript VM.



It “kind of works.” Michael was honest—it still has issues, it’s far from Chromium parity—but simple websites render quickly and largely correctly. They were astonished it worked at all.



Building a browser engine is notoriously one of the hardest things in software engineering. There are only three rendering engines in the world: Chromium, Gecko, and WebKit. Each represents thousands of engineer-years of work. Now
there’s a fourth, built by a single agent running for a week.



**Who’s involved:**



The browser doesn’t compete with Chrome. It’s not going to ship. But that’s not the point. The point is where the capability curve is at—and it’s only possible because coding has the properties that make agents work: clear success
criteria, the ability to retry, and feedback loops.



Here’s the larger story behind the Claude Code explosion: people think about it as “is it Claude Code or Codex?” I’m stepping back and realizing that the capabilities in Opus 4.5 and GPT-5.2 have crossed a tipping point for builders.
The excitement isn’t tool-driven. It’s about the capabilities these tools are enabling all of us to unlock together. That’s why I deliberately highlighted stories from both Claude and ChatGPT—the enthusiasm isn’t about one tool. It’s about what’s now possible.



**Why it matters:**



Coding is progressing quickly because it’s easy to retry, easy to see success criteria, and easy to run feedback loops. The bigger challenge of 2026 is how AI agents will progress in domains where feedback loops aren’t as consistent
and success criteria are more ambiguous—like the rest of knowledge work.



This week, Anthropic released Claude Cowork, positioned as “Claude Code for the rest of your work.” It’s a sandboxed environment where Claude can access files, execute actions, and complete multi-step tasks. The positioning acknowledges
something important: Claude Code succeeded not because it was a coding tool, but because it was an execution environment with the right constraints. Cowork attempts to bring those constraints to other domains.



Whether it works depends on whether users can define success criteria for non-coding tasks. That’s hard. What does “done” mean for “organize my project files”? Without clear success criteria, the system can’t self-correct.



The encouraging sign: Anthropic has done training so that common work tasks can be invoked with generally correct English that isn’t very precise. If you say “please make me a nice presentation using this data,” the model can get
to something pretty good. That still leaves room for people who want excellent work to get better at prompting, defining outputs, and defining correctness—and to get extraordinary results from tools like Cowork.



**What to watch:**



The practical implication: if you’re building AI into workflows, start by asking what your success criteria are. If you can define a clear test—”does the code pass the test suite,” “does this claim meet CMS criteria”—AI can help
reliably. If you can’t define a test, AI will be inconsistent regardless of model sophistication. Most valuable work doesn’t have objective success criteria. That’s why humans do it. The AI opportunity isn’t replacing human judgment, but automating the tasks
where human judgment isn’t actually needed.







##
**What Actually Compounds**



The AI industry spent the last three years building capability. Models got bigger. Benchmarks improved. Demos got more impressive. The assumption was that capability would translate into value—that better models would automatically
mean better products and more revenue.



That assumption is being tested this year. We’re finding out whether healthcare products matter, whether Claude Cowork works, whether physical AI scales. The AI industry as a whole is discovering what’s actually compounding and valuable
out of all the experimentation of the past couple years. And we, as the users and builders, get to be part of figuring out what truly has value here.



What I’ve come to believe: capability without execution doesn’t compound. A model that can theoretically do anything but practically completes nothing is not a product—it’s a demo. The companies that understand this are pulling ahead
of the ones still optimizing for benchmark performance.



Healthcare products matter not because AI is smarter at medicine, but because prior authorization is a bounded task with clear success criteria. Claude Code matters not because Claude is smarter at coding, but because code has objective
tests that enable retry loops. Physical AI is becoming interesting not because robots are suddenly capable, but because the combination of foundation models, simulation, and edge inference is creating execution infrastructure that didn’t exist before. The
training data story matters because capability improvement now requires data that doesn’t exist in accessible form.



The LeCun departure matters because even the people who built this technology are disagreeing publicly about whether current approaches will continue working.



What compounds is building systems where AI actually completes work reliably, in domains with clear success criteria, with feedback loops that enable improvement over time. Everything else is positioning and narrative.



So if I leave you with one thing: if you’re in physical work at all, robotics needs to be on your mind. The flywheel is starting to turn. And if you’re in software at all, you need to play with Claude Cowork. Both of those are big
stories that have to do with that compounding piece we all get to be part of.



Get building. That’s the news for the week.



References: [
https://www.perplexity.ai/search/please-prepare-a-comprehensive-vYEzj2boTgKoqMGBuVDu_Q#0](https://substack.com/redirect/539d2b43-be3b-43b8-85de-b58a25d992e6?j=eyJ1IjoiOHIxaDEifQ.bBvEbuUaT64-3FYFS8XubQvPw9CPsnWNsoHgk_rgvzU)


##
[Grab the
Prompt: “What Compounds” Detector](https://substack.com/redirect/36327b36-ffef-4e8f-a6f7-d40d91e3e73e?j=eyJ1IjoiOHIxaDEifQ.bBvEbuUaT64-3FYFS8XubQvPw9CPsnWNsoHgk_rgvzU)



The failure mode this prevents: you read about Claude Code, the robotics flywheel, the training data scramble, and walk away with vague competitive anxiety but no plan for you to actually act on.




This prompt forces a single decision—not five loops that might apply, one loop that matters for your context—and caps the output at a 14-day experiment you can actually run. It requires you to define what “done” looks like in your
world, because if you can’t define done, AI can’t help you compound. Before it recommends anything, it audits which assumptions in this week’s coverage might be wrong and how that would change the advice. And it makes you name three things to stop doing, because
compounding requires saying no to the stuff that doesn’t. Fill in everything and you get a tight operating plan. Fill in nothing and you still get a best-guess with assumptions labeled. Either way, you leave with one loop to build.






I make this Substack thanks to readers like you!
[
Learn about all my Substack tiers here](https://substack.com/redirect/b360bf14-0f3b-4847-ab8d-ef9296fd53a5?j=eyJ1IjoiOHIxaDEifQ.bBvEbuUaT64-3FYFS8XubQvPw9CPsnWNsoHgk_rgvzU) and
[
grab my prompt tool here](https://substack.com/redirect/901e61fa-a5b3-4f3e-8d4b-47934f7a9973?j=eyJ1IjoiOHIxaDEifQ.bBvEbuUaT64-3FYFS8XubQvPw9CPsnWNsoHgk_rgvzU)





[**Subscribed**](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9uYXRlc25ld3NsZXR0ZXIuc3Vic3RhY2suY29tL2FjY291bnQiLCJwIjoxODQ3ODI2MTQsInMiOjEzNzMyMzEsImYiOmZhbHNlLCJ1IjoxNDY5ODU0OSwiaWF0IjoxNzY4NjY1OTE5LCJleHAiOjIwODQyNDE5MTksImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.-E4i11h59llUHNVHRNPD0-bQ_F3CGEePN3euNbZHSmQ?)











[](https://substack.com/redirect/12b48785-f707-4080-95cf-9c738d74c6eb?j=eyJ1IjoiOHIxaDEifQ.bBvEbuUaT64-3FYFS8XubQvPw9CPsnWNsoHgk_rgvzU)











Invite your friends and earn rewards


If you enjoy Nate’s Substack, share it with your friends and earn rewards when they subscribe.



[**Invite
Friends**](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9uYXRlc25ld3NsZXR0ZXIuc3Vic3RhY2suY29tL2xlYWRlcmJvYXJkP3JlZmVycmVyX3Rva2VuPThyMWgxJnI9OHIxaDEmdXRtX2NhbXBhaWduPWVtYWlsLWxlYWRlcmJvYXJkIiwicCI6MTg0NzgyNjE0LCJzIjoxMzczMjMxLCJmIjpmYWxzZSwidSI6MTQ2OTg1NDksImlhdCI6MTc2ODY2NTkxOSwiZXhwIjoyMDg0MjQxOTE5LCJpc3MiOiJwdWItMCIsInN1YiI6ImxpbmstcmVkaXJlY3QifQ.r__vbQ7jzypOlsxQkz08sCqWYUkSJiUn2Wzg-yz002Q?&utm_source=substack&utm_medium=email&utm_content=postcta)


























[Like](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=substack&isFreemail=false&submitLike=true&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJyZWFjdGlvbiI6IuKdpCIsImlhdCI6MTc2ODY2NTkxOSwiZXhwIjoxNzcxMjU3OTE5LCJpc3MiOiJwdWItMTM3MzIzMSIsInN1YiI6InJlYWN0aW9uIn0.fUSTde1UTZzYpF_vf5fyIUCfYwJj6zgvxAN1ZNvmq5U&utm_medium=email&utm_campaign=email-reaction&r=8r1h1)













[Comment](https://substack.com/app-link/post?publication_id=1373231&post_id=184782614&utm_source=substack&utm_medium=email&isFreemail=false&comments=true&token=eyJ1c2VyX2lkIjoxNDY5ODU0OSwicG9zdF9pZCI6MTg0NzgyNjE0LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MTc3MTI1NzkxOSwiaXNzIjoicHViLTEzNzMyMzEiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.gKpjoxOtgmRE-LPIWEjgs8ip-_BybZXgPfCMuebtQPQ&r=8r1h1&utm_campaign=email-half-magic-comments&action=post-comment&utm_source=substack&utm_medium=email)













[Restack](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9vcGVuLnN1YnN0YWNrLmNvbS9wdWIvbmF0ZXNuZXdzbGV0dGVyL3AvaS1yZWFkLTIwMC1haS1hbm5vdW5jZW1lbnRzLXNvLXlvdT91dG1fc291cmNlPXN1YnN0YWNrJnV0bV9tZWRpdW09ZW1haWwmdXRtX2NhbXBhaWduPWVtYWlsLXJlc3RhY2stY29tbWVudCZhY3Rpb249cmVzdGFjay1jb21tZW50JnI9OHIxaDEmdG9rZW49ZXlKMWMyVnlYMmxrSWpveE5EWTVPRFUwT1N3aWNHOXpkRjlwWkNJNk1UZzBOemd5TmpFMExDSnBZWFFpT2pFM05qZzJOalU1TVRrc0ltVjRjQ0k2TVRjM01USTFOemt4T1N3aWFYTnpJam9pY0hWaUxURXpOek15TXpFaUxDSnpkV0lpT2lKd2IzTjBMWEpsWVdOMGFXOXVJbjAuZ0twam94T3RnbVJFLUxQSVdFamdzOGlwLV9CeWJaWGdQZkNNdWVidFFQUSIsInAiOjE4NDc4MjYxNCwicyI6MTM3MzIzMSwiZiI6ZmFsc2UsInUiOjE0Njk4NTQ5LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MjA4NDI0MTkxOSwiaXNzIjoicHViLTAiLCJzdWIiOiJsaW5rLXJlZGlyZWN0In0.5Re15-XnH2TuelV58mbGo5GOCZ11V5mO0IkJy-VzOJ8?&utm_source=substack&utm_medium=email)






































© 2026 Nate

548 Market Street PMB 72296, San Francisco, CA 94104

[Unsubscribe](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9uYXRlc25ld3NsZXR0ZXIuc3Vic3RhY2suY29tL2FjdGlvbi9kaXNhYmxlX2VtYWlsP3Rva2VuPWV5SjFjMlZ5WDJsa0lqb3hORFk1T0RVME9Td2ljRzl6ZEY5cFpDSTZNVGcwTnpneU5qRTBMQ0pwWVhRaU9qRTNOamcyTmpVNU1Ua3NJbVY0Y0NJNk1UZ3dNREl3TVRreE9Td2lhWE56SWpvaWNIVmlMVEV6TnpNeU16RWlMQ0p6ZFdJaU9pSmthWE5oWW14bFgyVnRZV2xzSW4wLjJmOW9UQ21HbmRzbmg2dUMtMkFIZ1YwTGhpczMxSlhUMFh6LUM2OTBIQUkiLCJwIjoxODQ3ODI2MTQsInMiOjEzNzMyMzEsImYiOmZhbHNlLCJ1IjoxNDY5ODU0OSwiaWF0IjoxNzY4NjY1OTE5LCJleHAiOjIwODQyNDE5MTksImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.ubBeMIqibHT_rlNO8Tz90CnH_bqlm9UqmaQrH5v5gzU?)




[](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9zdWJzdGFjay5jb20vc2lnbnVwP3V0bV9zb3VyY2U9c3Vic3RhY2smdXRtX21lZGl1bT1lbWFpbCZ1dG1fY29udGVudD1mb290ZXImdXRtX2NhbXBhaWduPWF1dG9maWxsZWQtZm9vdGVyJmZyZWVTaWdudXBFbWFpbD1kc255ZGVyQGN5ZGNvci5jb20mcj04cjFoMSIsInAiOjE4NDc4MjYxNCwicyI6MTM3MzIzMSwiZiI6ZmFsc2UsInUiOjE0Njk4NTQ5LCJpYXQiOjE3Njg2NjU5MTksImV4cCI6MjA4NDI0MTkxOSwiaXNzIjoicHViLTAiLCJzdWIiOiJsaW5rLXJlZGlyZWN0In0.KPIdkHJixc-TSSA54kw19j1zuZpiu2qC9aSjbJnlAcw?)















This message and any attached documents contains confidential and/or proprietary information of Cydcor LLC and/or its subsidiaries, agents, vendors, subcontractors and clients, and is not to be shared with others without the prior written consent of Cydcor
LLC. This information may not be reproduced, copied, disseminated or used for any purpose other than the purpose for which it was delivered to the recipient, without prior written consent of Cydcor LLC. Upon the request of Cydcor LLC, this information must
be, without delay, returned or destroyed, in accordance with the instructions of Cydcor LLC., without the recipient retaining copies or notes of any kind or nature of this document or derived from it. If you are not the intended recipient, you may not read,
copy, distribute, or use this information. If you are not the intended recipient, please notify the sender by return email and immediately delete this message.

---
*Captured via gmail-fetch from forwarded Substack email*
